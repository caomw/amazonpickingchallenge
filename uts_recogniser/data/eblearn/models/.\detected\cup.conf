################################################################################
# important training parameters (others are described later below)
eta=.000005
epoch_mode=1
iterations=20

# training data ################################################################
root=prepared_data/
train_dsname=cup+bg_train
val_dsname=cup+bg_val

train=prepared_data//cup+bg_train_data.mat
train_labels=prepared_data//cup+bg_train_labels.mat
train_classes=prepared_data//cup+bg_train_classes.mat
# train_size = 1000            # limit number of samples

val=prepared_data//cup+bg_val_data.mat
val_labels=prepared_data//cup+bg_val_labels.mat
val_classes=prepared_data//cup+bg_val_classes.mat
# val_size = 100                # limit number of samples


# network ######################################################################
classification=1
input_thickness=3
arch=resizepp0,conv0,addc0,tanh0,abs0,wstd0,subs1,addc1,tanh1,conv2,addc2,tanh2,abs2,wstd2,subs3,addc3,tanh3,conv4,addc4,tanh4,linear7,addc7,tanh7
nonlin=tanh


# layers
c0=conv0,addc0,tanh0,abs0,wstd0
s1=subs1,addc1,tanh1
c2=conv2,addc2,tanh2,abs2,wstd2
s3=subs3,addc3,tanh3
#c4 = conv4,addc4,${nonlin}4,abs4,wstd4

c4=conv4,addc4,tanh4
f5=linear5,addc5,tanh5

f7=linear7,addc7,tanh7

# energies & answers ###########################################################
trainer=trainable_module1
trainable_module1_energy=l2_energy
answer=class_answer
background_name=bg

# preprocessing modules
pp_yp=rgb_to_ypuv0
rgb_to_ypuv0_kernel=7x7
resizepp0_pp=rgb_to_ypuv0
pp_train=
pp_detect=resizepp0

# modules parameters
inputh=64
inputw=64
conv0_kernel=9x9
conv0_stride=1x1
conv0_table=
conv0_table_in=3
conv0_table_out=6
wstd0_kernel=5x5
subs1_kernel=2x2
subs1_stride=2x2
addc1_weights=
conv2_kernel=9x9
conv2_stride=1x1
conv2_table=../table_6_16_connect_60.mat
conv2_table_in=thickness
conv2_table_out=
conv2_weights=
addc2_weights=
diag2_weights=
wstd2_kernel=5x5
subs3_kernel=2x2
subs3_stride=2x2
addc3_weights=
conv4_kernel=10x10
conv4_stride=1x1
conv4_table_in=thickness
conv4_table_out=100
linear5_in=thickness
linear5_out=noutputs

linear7_in=thickness
linear7_out=noutputs

# tables #######################################################################
table0_max=6
table1=../table_6_16_connect_60.mat

# preprocessing ################################################################
resize=mean
normalization_size=7

# training params ##############################################################
reg_l1=
reg_l2=

inertia=0.0
anneal_value=0.0
annea_period=0
gradient_threshold=0.0

epoch_show_modulo=1000
no_testing_test=0
no_training_test=1
test_only=0
sample_probabilities=0
hardest_focus=0
ignore_correct=0
min_sample_weight=0
per_class_norm=1
shuffle_passes=1
balanced_training=1
random_class_order=1
target_factor=1
save_pickings=0
binary_target=0
save_weights=1
save_confusion=0
keep_outputs=0
fixed_randomization=1
training_precision=double

# tracking ####################################################################
mainsleep=5
smooth_factor=1.0
# display tracking
tracking_display=0

# training display #############################################################
display=1
show_conf=1
show_train=0
show_train_ninternals=1
show_train_errors=0
show_train_correct=0
show_val_errors=1
show_val_correct=1
show_hsample=5
show_wsample=18
show_wait_user=0

# detection ####################################################################
weights=net00020.mat
classes=prepared_data//cup+bg_val_classes.mat
input_dir=test
#input_list = 396.jpg
#show_conf = 1
input_height=480
#input_width=640		#-1#160#640
#input_min=100
input_max=800
# multi-scaling type. 0: manually set each scale sizes, 1: manually set each
# scale step, 2: number of scales between min and max, 3: step factor between
# min and max, 4: 1 scale, the original image size.
scaling_type=3
# scaling ratio between scales
scaling=1.2
# scale factor of maximum resolution of the original resolution
max_scale=0.4
# scale factor of minimum resolution of the original resolution
min_scale=1.4
# number of detection threads
nthreads=1
# randomize image input list (only works for 'directory' camera).
input_random=0
# number of passes on the image input list (only works for 'directory' camera).
input_npasses=1
# height factor to apply to bounding boxes
bbhfactor=1
# width factor to apply to bounding boxes
bbwfactor=1
# prune overlapping bounding boxes or not
pruning=1
# minimum height ratio with smallest bbox to declare overlap
bbh_overlap=.67
# minimum width ratio with smallest bbox to declare overlap
bbw_overlap=0
hzpad=.5
wzpad=.5
mem_optimization=1
confidence_type=2

# detection display ############################################################
# output saving and display
output_dir=./result
detection_dir=/detect
bbox_saving=2
save_bbox_period=1
# save each classified frame and make a video out of it
save_video=0
# fps at which video should be constructed
save_video_fps=0
# if loaded a video and equal to 1, reuse video's fps
use_original_fps=0
# enable or disable display
display=1
display_threads=1
# only show classified input
minimal_display=0
silent=0
sync_outputs=0
# display internal states of network
display_states=0
display_min=-1.7
display_max=1.7
display_in_min=0
display_in_max=255
display_bb_transparency=0
display_sleep=300
ninternals=1

# camera options: v4l2 opencv shmem video directory
camera=directory

threshold=0.8
pre_threshold=-1
post_threshold=0.8
nms=3
pre_hfact=1
pre_wfact=1
post_hfact=1
post_wfact=1
woverh=1
max_hcenter_dist=.3
max_wcenter_dist=.3
vote_max_overlap=.5
vote_max_hcenter_dist=.5
vote_max_wcenter_dist=.3

display_sleep=300
scaling=1.2
# multi-scaling type. 0: manually set each scale sizes, 1: manually set each
# scale step, 2: number of scales between min and max, 3: step factor between
# min and max, 4: 1 scale, the original image size.
scaling_type=3
max_scale=0.4
min_scale=1.4
#input_max = 288
show_extracted=2



current_dir=./ # variable added by metarun
root2=./ # variable added by metarun
run_type=detect # variable added by metarun
